{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/medinLaVie/workshops/blob/master/mongodb_rag_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6lDguU6yDaK"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mongodb-developer/ai-agents-lab-notebooks/blob/main/notebook_template.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8aPzrBYyDaL"
      },
      "source": [
        "[![Lab Documentation and Solutions](https://img.shields.io/badge/Lab%20Documentation%20and%20Solutions-purple)](https://mongodb-developer.github.io/ai-agents-lab/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kMALXaMv-MS"
      },
      "source": [
        "# Step 1: Install libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxTXczeTghzU",
        "outputId": "f26e5807-f655-4d25-f2b2-4abc8948c028"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m975.5/975.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m669.1/669.1 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m332.8/332.8 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.4/127.4 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.8/81.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.4/327.4 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain langchainhub langchain-community langchain-fireworks \\\n",
        "langchain-huggingface langchain-mongodb arxiv pymupdf duckduckgo-search datasets pymongo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RM8rg08YhqZe"
      },
      "source": [
        "# Step 2: Setup prerequisites\n",
        "\n",
        "Replace:\n",
        "\n",
        "- `<CODE_BLOCK_1>` with your **MongoDB connection string**\n",
        "- `<CODE_BLOCK_2>` with your **Fireworks API key**\n",
        "- `<CODE_BLOCK_3>` with your **LangSmith API key**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jv5R6kXwyDaM"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXLWCWEghuOX"
      },
      "outputs": [],
      "source": [
        "# Retain the quotes (\"\") when pasting the URI\n",
        "MONGODB_URI = \"<CODE_BLOCK_1>\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTjVQabVyDaN"
      },
      "outputs": [],
      "source": [
        "# Retain the quotes (\"\") when pasting the API key\n",
        "os.environ[\"FIREWORKS_API_KEY\"] = \"<CODE_BLOCK_2>\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQe-qsmSyDaN"
      },
      "outputs": [],
      "source": [
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "# Retain the quotes (\"\") when pasting the API key\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = \"<CODE_BLOCK_3>\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUf3jtFzO4-V"
      },
      "source": [
        "# Step 3: Create a knowledge base\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yg1zj3xsyDaN"
      },
      "source": [
        "### Download the dataset from Hugging Face\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWPR5jVtyDaN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from pymongo import MongoClient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pq4SA6r7O30i"
      },
      "outputs": [],
      "source": [
        "data = load_dataset(\"mongodb-eai/arxiv-embeddings\")\n",
        "dataset_df = pd.DataFrame(data[\"train\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKVn0MvqyDaN"
      },
      "outputs": [],
      "source": [
        "# Preview the dataset -- notice that the dataset already has an `embedding` column, which consists of embeddings of the paper abstracts.\n",
        "dataset_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwSPGfjLyDaO"
      },
      "source": [
        "### Ingest data into MongoDB\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMwdw41iyDaO"
      },
      "source": [
        "📚 https://pymongo.readthedocs.io/en/stable/api/pymongo/mongo_client.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2gHwRjMfJlO"
      },
      "outputs": [],
      "source": [
        "# Initialize a MongoDB Python client\n",
        "client = <CODE_BLOCK_4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYAsS3qJyDaO"
      },
      "outputs": [],
      "source": [
        "# Name of the database -- Change if needed or leave as is\n",
        "DB_NAME = \"mongodb_agents_lab\"\n",
        "# Name of the collection -- Change if needed or leave as is\n",
        "COLLECTION_NAME = \"knowledge\"\n",
        "# Name of the vector search index -- Change if needed or leave as is\n",
        "ATLAS_VECTOR_SEARCH_INDEX_NAME = \"vector_index\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZFG100ryDaO"
      },
      "source": [
        "📚 https://pymongo.readthedocs.io/en/stable/tutorial.html#getting-a-collection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPrvRno7yDaO"
      },
      "outputs": [],
      "source": [
        "# Connect to the collection defined above using the MongoDB client\n",
        "collection = <CODE_BLOCK_5>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbMBd96JyDaO"
      },
      "source": [
        "📚 https://pymongo.readthedocs.io/en/stable/api/pymongo/collection.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJkyy9UbffZT"
      },
      "outputs": [],
      "source": [
        "# Bulk delete all existing records from the collection defined above -- should be a one-liner\n",
        "<CODE_BLOCK_6>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWT4UjQWyDaO"
      },
      "outputs": [],
      "source": [
        "# Ingest data into the collection\n",
        "records = dataset_df.to_dict(\"records\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3m9Tcd7yDaO"
      },
      "source": [
        "📚 https://pymongo.readthedocs.io/en/stable/api/pymongo/collection.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zko5dJXFyDaO"
      },
      "outputs": [],
      "source": [
        "# Bulk insert `records` into the collection defined above -- should be a one-liner\n",
        "<CODE_BLOCK_7>\n",
        "\n",
        "print(\"Data ingestion into MongoDB completed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xA3iZ0FpyDaO"
      },
      "source": [
        "# Step 4: Create a vector search index\n",
        "\n",
        "Follow the instructions in the documentation to create a Vector Search index in the Atlas UI.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDIPmcdhyDaO"
      },
      "source": [
        "# Step 5: Instantiate chat completion LLM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_g_viQZ_yDaO"
      },
      "outputs": [],
      "source": [
        "from langchain_fireworks import ChatFireworks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gh5zIIy-yDaO"
      },
      "source": [
        "📚 https://python.langchain.com/v0.1/docs/integrations/chat/fireworks/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zqt-mWjyDaO"
      },
      "outputs": [],
      "source": [
        "# Set the temperature for the chat model to 0.0 and max tokens to 1024\n",
        "llm = <CODE_BLOCK_8>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZfheX5FiIhU"
      },
      "source": [
        "# Step 6: Create agent tools\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "InM79hLgyDaO"
      },
      "outputs": [],
      "source": [
        "from langchain.tools import tool\n",
        "from langchain_community.document_loaders import ArxivLoader\n",
        "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_mongodb import MongoDBAtlasVectorSearch\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhDlhlC4yDaO"
      },
      "source": [
        "### Tool to fetch paper metadata from Arxiv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KCp0iDqyDaP"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def get_paper_metadata_from_arxiv(topic: str) -> list:\n",
        "    \"\"\"\n",
        "    Fetch and return paper metadata for 5 Arxiv papers matching the given topic, for example: Retrieval Augmented Generation.\n",
        "\n",
        "    Args:\n",
        "    topic (str): The topic to find papers for on Arxiv.\n",
        "\n",
        "    Returns:\n",
        "    list: Metadata about the papers matching the topic.\n",
        "    \"\"\"\n",
        "    docs = ArxivLoader(query=topic, load_max_docs=5).load()\n",
        "    # Extract just the metadata from each document\n",
        "    metadata = [doc.metadata for doc in docs]\n",
        "    return metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XDFB2OZyDaP"
      },
      "source": [
        "### Tool to fetch the summary of a paper\n",
        "\n",
        "📚 https://python.langchain.com/v0.1/docs/integrations/document_loaders/arxiv/\n",
        "\n",
        "📚 https://api.python.langchain.com/en/latest/document_loaders/langchain_community.document_loaders.arxiv.ArxivLoader.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zZRE_S2yDaP"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def get_paper_summary_from_arxiv(id: str) -> str:\n",
        "    \"\"\"\n",
        "    Fetch and return the summary for a single research paper from Arxiv given the paper ID, for example: 1605.08386.\n",
        "\n",
        "    Args:\n",
        "    id (str): The paper ID.\n",
        "\n",
        "    Returns:\n",
        "    str: Summary of the paper.\n",
        "    \"\"\"\n",
        "    # Create a tool that uses the `ArxivLoader` document loader to return the paper summary given the paper ID (`id`).\n",
        "    # NOTE:\n",
        "        # Use the `get_summaries_as_docs` method of `ArxivLoader`\n",
        "        # Handle the case where the paper ID is invalid i.e., the number of docs returned from `ArxivLoader` are 0.\n",
        "    <CODE_BLOCK_9>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8TBf_RDyDaP"
      },
      "source": [
        "### Tool to answer questions based on information in the knowledge base\n",
        "\n",
        "In **Step 3**, we created a knowledge base for the agent. This tool should use the knowledge base to help the agent answer questions about topics. To do this, you will need to:\n",
        "\n",
        "- Create a MongoDB vector store\n",
        "\n",
        "- Get relevant documents from the vector store\n",
        "\n",
        "- Create a RAG chain that uses the retrieved documents and the LLM from **Step 5** to answer questions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSaZgOnXyDaP"
      },
      "source": [
        "#### Create a MongoDB Vector Store\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BaoGg-payDaP"
      },
      "outputs": [],
      "source": [
        "# Embedding model to use for the vector store -- DO NOT CHANGE\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"mixedbread-ai/mxbai-embed-large-v1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7cLux-wyDaS"
      },
      "source": [
        "📚 https://api.python.langchain.com/en/latest/_modules/langchain_mongodb/vectorstores.html#MongoDBAtlasVectorSearch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xy-g9CHQyDaS"
      },
      "outputs": [],
      "source": [
        "# Create a MongoDBAtlas vector store\n",
        "# Use the `from_connection_string` method of the MongoDBAtlasVectorSearch class.\n",
        "# Arguments: connection_string, namespace, embedding, index_name, text_key\n",
        "# NOTE: Use variables defined in Steps 2, 3 and this step as values for the above arguments\n",
        "vector_store = <CODE_BLOCK_10>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psm2UiCGyDaS"
      },
      "source": [
        "#### Get relevant documents from the vector store\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_SMA8IDyDaS"
      },
      "source": [
        "📚 https://github.com/langchain-ai/langchain/blob/master/libs/partners/mongodb/langchain_mongodb/vectorstores.py#L187\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfj1KcOzyDaS"
      },
      "outputs": [],
      "source": [
        "# Define a function to retrieve documents with a similarity score greater than 0.8 from the `vector_store`\n",
        "# Use the `similarity_search_with_score` method to get similar documents with their scores\n",
        "# Filter the retrieved list of documents to only return those with a score > 0.8\n",
        "def get_context(query):\n",
        "    <CODE_BLOCK_11>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0M1FGY__yDaS"
      },
      "source": [
        "#### Create a RAG chain\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZyz2PunyDaS"
      },
      "source": [
        "📚 https://python.langchain.com/v0.1/docs/use_cases/question_answering/quickstart/\n",
        "\n",
        "📚 https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.base.RunnableLambda.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LfoQQEmyDaS"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def answer_questions_about_topics(query: str) -> list:\n",
        "    \"\"\"\n",
        "    Answer questions about a given topic based on information in the knowledge base.\n",
        "\n",
        "    Args:\n",
        "    query (str): User query about a topic.\n",
        "\n",
        "    Returns:\n",
        "    str: Information about the topic.\n",
        "    \"\"\"\n",
        "    # Create a RAG chain that uses the `llm` we instantiated in Step 4 and the `get_context` function above\n",
        "    # NOTE: Use `RunnableLambda` to convert the `get_context` function  into a Runnable\n",
        "    # Return the response of running `invoke` on the chain with `query` as an argument\n",
        "    <CODE_BLOCK_12>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQv_aXf5yDaS"
      },
      "outputs": [],
      "source": [
        "# Create the list of tools\n",
        "tools = [\n",
        "    get_paper_metadata_from_arxiv,\n",
        "    get_paper_summary_from_arxiv,\n",
        "    answer_questions_about_topics,\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtlKgNLayDaS"
      },
      "source": [
        "### Test out the tools\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "up5wuqYQyDaS"
      },
      "outputs": [],
      "source": [
        "# Test out the `get_paper_metadata_from_arxiv` tool\n",
        "get_paper_metadata_from_arxiv.invoke(\"Retrieval Augmented Generation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sI9dSAxSyDaS"
      },
      "outputs": [],
      "source": [
        "# Test out the `get_paper_summary_from_arxiv` tool with paper ID 1808.09236\n",
        "<CODE_BLOCK_13>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Esfzy9pJyDaS"
      },
      "outputs": [],
      "source": [
        "# Test out the `get_paper_summary_from_arxiv` with an invalid paper ID eg: 808.09236\n",
        "<CODE_BLOCK_14>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXuYeWFJyDaS"
      },
      "outputs": [],
      "source": [
        "# Test out the `answer_questions_about_topics` tool with the topic \"Partial cubes\"\n",
        "<CODE_BLOCK_15>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXq4MFdAyDaS"
      },
      "outputs": [],
      "source": [
        "# Test out the `answer_questions_about_topics` tool with a topic that is not present in the knowledge base eg:\"Tree of Thoughts\"\n",
        "<CODE_BLOCK_16>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xb5MusOyDaS"
      },
      "source": [
        "# 🦹 Use web search to get information\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAYiSujfyDaS"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "from langchain.docstore.document import Document"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgDo_KMTyDaS"
      },
      "source": [
        "📚 https://python.langchain.com/v0.2/docs/integrations/tools/ddg/\n",
        "\n",
        "📚 https://stackoverflow.com/questions/76551067/how-to-create-a-langchain-doc-from-an-str\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rpbu-R42yDaS"
      },
      "outputs": [],
      "source": [
        "# Extend the `get_context` function from Step 6 to use DuckDuckGo search if no documents are retrieved from the knowledge base\n",
        "# NOTE: The result from DuckDuckGo search is a string and will need to be converted to a LangChain document for downstream use\n",
        "def get_context(query):\n",
        "    <CODE_BLOCK_17>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOYDeWfOyDaT"
      },
      "outputs": [],
      "source": [
        "answer_questions_about_topics.invoke(\"Tree of Thoughts\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XILIae5yDaT"
      },
      "source": [
        "# Step 7: Create a basic tool-calling agent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGsTA0QjyDaT"
      },
      "outputs": [],
      "source": [
        "from langchain.tools.render import render_text_description\n",
        "from langchain_core.prompts import MessagesPlaceholder\n",
        "from langchain.agents import AgentExecutor, create_tool_calling_agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4oGylpgyDaT"
      },
      "source": [
        "📚 https://api.python.langchain.com/en/latest/tools/langchain.tools.render.render_text_description.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmFWwh-XyDaT"
      },
      "outputs": [],
      "source": [
        "# Try out a simple system prompt\n",
        "# Use the `render_text_description` method to include the list of tools the agent can access, in the prompt.\n",
        "system_message = <CODE_BLOCK_18>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ifx2Erh1yDaT"
      },
      "source": [
        "### 🦹 CoT prompting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tY8Se8H2yDaT"
      },
      "outputs": [],
      "source": [
        "# system_message = f\"\"\"Given a question, write out in a step-by-step manner your reasoning\n",
        "# for how you will solve the problem to be sure that your conclusion is correct.\n",
        "# Avoid simply stating the correct answer at the outset. You can answer directly if the user\n",
        "# is greeting you or similar. Otherwise, you have access to the following tools:\n",
        "\n",
        "# {render_text_description(tools)}\n",
        "\n",
        "# Begin!\n",
        "# \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16diV9rvyDaT"
      },
      "source": [
        "📚 https://python.langchain.com/v0.1/docs/modules/agents/agent_types/tool_calling/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RY13DrVXFDrm"
      },
      "outputs": [],
      "source": [
        "# Refer to the `Create Agent` and `Run Agent` sections in the docs above to craft a prompt, initialize an agent, and an agent executor\n",
        "# NOTE:\n",
        "    # Use the `system_message` above as the system prompt\n",
        "    # Do not include chat history in the prompt right now\n",
        "    # Name the agent executor object `agent_executor`\n",
        "<CODE_BLOCK_19>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISnnYIY-yDaT"
      },
      "source": [
        "📚 https://python.langchain.com/v0.1/docs/modules/agents/how_to/handle_parsing_errors/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7C7f01RyDaT"
      },
      "outputs": [],
      "source": [
        "# Test that the agent works as expected.\n",
        "# If it runs into parsing errors, add appropriate arguments to the `agent_executor` object and try again.\n",
        "agent_executor.invoke({\"input\": \"Give me papers on the topic prompt compression.\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPu1crSTyDaT"
      },
      "source": [
        "# Step 8: Create a ReAct agent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxY5vi2iyDaT"
      },
      "outputs": [],
      "source": [
        "from langchain import hub\n",
        "from langchain.agents import create_react_agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MR0Wjjs9yDaT"
      },
      "outputs": [],
      "source": [
        "# Pull a ready-made react prompt from LangChain hub -- Modify if needed\n",
        "prompt = hub.pull(\"hwchase17/react\")\n",
        "prompt.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owuc0HqWyDaT"
      },
      "source": [
        "📚 https://python.langchain.com/v0.1/docs/modules/agents/agent_types/react/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZKO3n77yDaT"
      },
      "outputs": [],
      "source": [
        "# Refer to the above docs to initialize a ReAct agent and the agent executor\n",
        "# NOTE:\n",
        "    # Use the `prompt` above as the agent prompt\n",
        "    # Do not include chat history in the prompt right now\n",
        "    # Name the agent executor object `agent_executor`\n",
        "<CODE_BLOCK_20>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBl2tQlkyDaT"
      },
      "source": [
        "📚 https://python.langchain.com/v0.1/docs/modules/agents/how_to/handle_parsing_errors/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kn4TfApLyDaT"
      },
      "outputs": [],
      "source": [
        "# Test that the agent works as expected.\n",
        "# If it runs into parsing errors, add appropriate arguments to the agent executor and try again.\n",
        "agent_executor.invoke({\"input\": \"Give me the summary for the paper 1808.09236.\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kabcCLjxyDaT"
      },
      "source": [
        "# 🦹 Create a custom agent without using abstractions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGJHKnU5yDaU"
      },
      "outputs": [],
      "source": [
        "from langchain.agents.output_parsers.tools import ToolsAgentOutputParser\n",
        "from langchain.agents.format_scratchpad.tools import (\n",
        "    format_to_tool_messages,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8WpBIRAyDaU"
      },
      "source": [
        "📚 https://python.langchain.com/v0.1/docs/modules/agents/how_to/custom_agent/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRcMYdYJyDaU"
      },
      "outputs": [],
      "source": [
        "# Refer to the docs above to build a custom agent without using the `create_tool_calling_agent` abstraction.\n",
        "# NOTE:\n",
        "    # Do not include chat history in the prompt right now\n",
        "    # Name the agent executor object `agent_executor`\n",
        "<CODE_BLOCK_21>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1udyF8JfyDaU"
      },
      "outputs": [],
      "source": [
        "agent_executor.invoke({\"input\": \"Give me papers on the topic prompt compression.\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4NU4ZjGl0WC"
      },
      "source": [
        "# Step 9: Add memory to agents using MongoDB\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lyL2FDUiyDaU"
      },
      "outputs": [],
      "source": [
        "from langchain_mongodb.chat_message_histories import MongoDBChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOiVJzJ1yDaU"
      },
      "source": [
        "📚 https://python.langchain.com/v0.2/docs/integrations/memory/mongodb_chat_message_history/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1A-3Fg1cjwyK"
      },
      "outputs": [],
      "source": [
        "# Define a function that returns an instance of `MongoDBChatMessageHistory`\n",
        "# Use variables defined in Steps 2 & 3 for the `connection_string` and `database_name` parameters\n",
        "# Choose a collection name of your choice to store the chat history\n",
        "def get_message_history(session_id: str) -> MongoDBChatMessageHistory:\n",
        "    <CODE_BLOCK_22>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSY8VwBUyDaU"
      },
      "source": [
        "📚 https://python.langchain.com/v0.1/docs/modules/agents/agent_types/tool_calling/#create-agent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wI4uBAmNF5ll"
      },
      "outputs": [],
      "source": [
        "# Refer to the above docs and modify the code below to include chat history\n",
        "system_message = f\"\"\"Answer the following questions as best you can.\n",
        "You can answer directly if the user is greeting you or similar.\n",
        "Otherwise, you have access to the following tools:\n",
        "\n",
        "{render_text_description(tools)}\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_message),\n",
        "        <CODE_BLOCK_23>,\n",
        "        (\"human\", \"{input}\"),\n",
        "        # Placeholders fill up a **list** of messages\n",
        "        MessagesPlaceholder(\"agent_scratchpad\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "agent = create_tool_calling_agent(llm, tools, prompt)\n",
        "\n",
        "agent_executor = AgentExecutor(\n",
        "    agent=agent, tools=tools, verbose=True, handle_parsing_errors=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCrvhQUMyDaU"
      },
      "source": [
        "📚 https://python.langchain.com/v0.1/docs/expression_language/how_to/message_history/#langsmith\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lp2kIHQ_yDaU"
      },
      "outputs": [],
      "source": [
        "# Look at the example in the docs above to add and manage chat history for the agent.\n",
        "agent_with_chat_history = <CODE_BLOCK_24>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sO8eAwiyDaU"
      },
      "outputs": [],
      "source": [
        "# Test the agent with chat history to make sure it works\n",
        "agent_with_chat_history.invoke(\n",
        "    {\"input\": \"Get me papers on Prompt Compression.\"},\n",
        "    config={\"configurable\": {\"session_id\": \"my-session\"}},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJB0jDs6yDaU"
      },
      "outputs": [],
      "source": [
        "# Invoke the agent with a follow-up question to make sure that the chat history is being used\n",
        "<CODE_BLOCK_25>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "RM8rg08YhqZe",
        "UUf3jtFzO4-V",
        "Sm5QZdshwJLN"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}